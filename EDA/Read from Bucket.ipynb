{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "babc89b4-4ad8-43ef-8380-a3586b13081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Logger configured - logs will be written to logs/eda.log\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Create logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Clear any existing handlers to avoid duplicates\n",
    "if logger.handlers:\n",
    "    logger.handlers.clear()\n",
    "\n",
    "# File handler - logs to file\n",
    "log_path = os.path.join(os.path.dirname(os.getcwd()), 'logs', 'eda.log')\n",
    "file_handler = logging.FileHandler(log_path, mode='a')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "file_handler.setFormatter(file_formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Console handler - minimal output to cell (optional)\n",
    "console_handler = logging.StreamHandler(sys.stdout)\n",
    "console_handler.setLevel(logging.WARNING)  # Only show warnings/errors in notebook\n",
    "console_formatter = logging.Formatter('%(levelname)s: %(message)s')\n",
    "console_handler.setFormatter(console_formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Helper function for flushing\n",
    "def log_and_flush(message, level='info'):\n",
    "    if level == 'info':\n",
    "        logger.info(message)\n",
    "    elif level == 'warning':\n",
    "        logger.warning(message)\n",
    "    elif level == 'error':\n",
    "        logger.error(message)\n",
    "    \n",
    "    for handler in logger.handlers:\n",
    "        handler.flush()\n",
    "\n",
    "print(\"✓ Logger configured - logs will be written to logs/eda.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f28fa0-53b6-4aac-9b69-9b9be91cc434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Config loaded\n",
      "\n",
      "==================================================\n",
      "✓ Spark Session Ready\n",
      "==================================================\n",
      "==================================================\n",
      "Current Configuration:\n",
      "==================================================\n",
      "App Name: NYC Taxi EDA\n",
      "Environment: development\n",
      "MinIO Endpoint: http://minio:9000\n",
      "S3 Bucket: nyc-taxi\n",
      "Spark Driver Memory: 3g\n",
      "Spark Executor Memory: 3g\n",
      "Spark Executor Instances: 3\n",
      "Spark Executor Cores: 2\n",
      "Log Level: INFO\n",
      "Log File: eda.log\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import importlib.util\n",
    "\n",
    "# ========== LOAD CONFIG FIRST ==========\n",
    "src_path = os.path.join(os.path.dirname(os.getcwd()), 'src')\n",
    "config_file = os.path.join(src_path, 'config.py')\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"config\", config_file)\n",
    "config_module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(config_module)\n",
    "\n",
    "Config = config_module.Config\n",
    "print(\"✓ Config loaded\")\n",
    "\n",
    "# ========== HELPER FUNCTION ==========\n",
    "def log_and_flush(message):\n",
    "    logger.info(message)\n",
    "    for handler in logger.handlers:\n",
    "        handler.flush()\n",
    "\n",
    "# ========== STOP EXISTING SPARK ==========\n",
    "try:\n",
    "    spark.stop()\n",
    "    log_and_flush(\"Stopped existing Spark session\")\n",
    "except:\n",
    "    log_and_flush(\"No existing Spark session to stop\")\n",
    "\n",
    "# ========== CREATE SPARK SESSION ==========\n",
    "log_and_flush(f\"Creating Spark session: {Config.APP_NAME}\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(Config.APP_NAME) \\\n",
    "    .config(\"spark.driver.memory\", Config.SPARK_DRIVER_MEMORY) \\\n",
    "    .config(\"spark.executor.memory\", Config.SPARK_EXECUTOR_MEMORY) \\\n",
    "    .config(\"spark.executor.instances\", Config.SPARK_EXECUTOR_INSTANCES) \\\n",
    "    .config(\"spark.executor.cores\", Config.SPARK_EXECUTOR_CORES) \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "log_and_flush(f\"Spark session created successfully (version {spark.version})\")\n",
    "\n",
    "# ========== CONFIGURE HADOOP FOR MINIO ==========\n",
    "log_and_flush(\"Configuring Hadoop for MinIO\")\n",
    "\n",
    "hadoop_conf = spark._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.endpoint\", Config.MINIO_ENDPOINT)\n",
    "hadoop_conf.set(\"fs.s3a.access.key\", Config.MINIO_ACCESS_KEY)\n",
    "hadoop_conf.set(\"fs.s3a.secret.key\", Config.MINIO_SECRET_KEY)\n",
    "hadoop_conf.set(\"fs.s3a.path.style.access\", \"true\")\n",
    "hadoop_conf.set(\"fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "hadoop_conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "\n",
    "log_and_flush(f\"Spark configured for environment: {Config.ENVIRONMENT}\")\n",
    "log_and_flush(f\"Using MinIO endpoint: {Config.MINIO_ENDPOINT}\")\n",
    "log_and_flush(f\"Reading from bucket: {Config.S3_BUCKET_NAME}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✓ Spark Session Ready\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Display configuration (on its own line!)\n",
    "Config.display_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65753669-b7bb-492b-a36f-452cc7cf63e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Objects inside 'nyc-taxi':\n",
      " - 2023/yellow_tripdata_2023-01.parquet (47673370 bytes)\n",
      " - 2023/yellow_tripdata_2023-02.parquet (47748012 bytes)\n",
      " - 2023/yellow_tripdata_2023-03.parquet (56127762 bytes)\n",
      " - 2023/yellow_tripdata_2023-04.parquet (54222699 bytes)\n",
      " - 2023/yellow_tripdata_2023-05.parquet (58654627 bytes)\n",
      " - 2023/yellow_tripdata_2023-06.parquet (54999465 bytes)\n",
      " - 2023/yellow_tripdata_2023-07.parquet (48361828 bytes)\n",
      " - 2023/yellow_tripdata_2023-08.parquet (48152353 bytes)\n",
      " - 2023/yellow_tripdata_2023-09.parquet (47895515 bytes)\n",
      " - 2023/yellow_tripdata_2023-10.parquet (59009059 bytes)\n",
      " - 2023/yellow_tripdata_2023-11.parquet (56094653 bytes)\n",
      " - 2023/yellow_tripdata_2023-12.parquet (56804275 bytes)\n",
      " - 2024/yellow_tripdata_2024-01.parquet (49961641 bytes)\n",
      " - 2024/yellow_tripdata_2024-02.parquet (50349284 bytes)\n",
      " - 2024/yellow_tripdata_2024-03.parquet (60078280 bytes)\n",
      " - 2024/yellow_tripdata_2024-04.parquet (59133625 bytes)\n",
      " - 2024/yellow_tripdata_2024-05.parquet (62553128 bytes)\n",
      " - 2024/yellow_tripdata_2024-06.parquet (59859922 bytes)\n",
      " - 2024/yellow_tripdata_2024-07.parquet (52299432 bytes)\n",
      " - 2024/yellow_tripdata_2024-08.parquet (51067350 bytes)\n",
      " - 2024/yellow_tripdata_2024-09.parquet (61170186 bytes)\n",
      " - 2024/yellow_tripdata_2024-10.parquet (64346071 bytes)\n",
      " - 2024/yellow_tripdata_2024-11.parquet (60658709 bytes)\n",
      " - 2024/yellow_tripdata_2024-12.parquet (61524085 bytes)\n",
      " - 2025/yellow_tripdata_2025-01.parquet (59158238 bytes)\n",
      " - 2025/yellow_tripdata_2025-02.parquet (60343086 bytes)\n",
      " - 2025/yellow_tripdata_2025-03.parquet (69964745 bytes)\n",
      " - 2025/yellow_tripdata_2025-04.parquet (67352824 bytes)\n",
      " - 2025/yellow_tripdata_2025-05.parquet (77837865 bytes)\n",
      " - 2025/yellow_tripdata_2025-06.parquet (73542954 bytes)\n",
      " - 2025/yellow_tripdata_2025-07.parquet (66943728 bytes)\n",
      " - 2025/yellow_tripdata_2025-08.parquet (62293743 bytes)\n",
      " - Clean_DF/_SUCCESS (0 bytes)\n",
      " - Clean_DF/part-00000-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (68545590 bytes)\n",
      " - Clean_DF/part-00001-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (62982710 bytes)\n",
      " - Clean_DF/part-00002-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (64745415 bytes)\n",
      " - Clean_DF/part-00003-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (64624200 bytes)\n",
      " - Clean_DF/part-00004-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (57843368 bytes)\n",
      " - Clean_DF/part-00005-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (58899602 bytes)\n",
      " - Clean_DF/part-00006-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (68853645 bytes)\n",
      " - Clean_DF/part-00007-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (66400906 bytes)\n",
      " - Clean_DF/part-00008-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (66525666 bytes)\n",
      " - Clean_DF/part-00009-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (63293821 bytes)\n",
      " - Clean_DF/part-00010-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (54526715 bytes)\n",
      " - Clean_DF/part-00011-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (64839937 bytes)\n",
      " - Clean_DF/part-00012-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (62997037 bytes)\n",
      " - Clean_DF/part-00013-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (62693623 bytes)\n",
      " - Clean_DF/part-00014-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (55321449 bytes)\n",
      " - Clean_DF/part-00015-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (67521098 bytes)\n",
      " - Clean_DF/part-00016-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (68648803 bytes)\n",
      " - Clean_DF/part-00017-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (62103200 bytes)\n",
      " - Clean_DF/part-00018-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (66317963 bytes)\n",
      " - Clean_DF/part-00019-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (63723862 bytes)\n",
      " - Clean_DF/part-00020-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (63964466 bytes)\n",
      " - Clean_DF/part-00021-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (64265055 bytes)\n",
      " - Clean_DF/part-00022-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (64152092 bytes)\n",
      " - Clean_DF/part-00023-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (118108840 bytes)\n",
      " - Clean_DF/part-00024-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (112274663 bytes)\n",
      " - Clean_DF/part-00025-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (114604854 bytes)\n",
      " - Clean_DF/part-00026-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (111938897 bytes)\n",
      " - Clean_DF/part-00027-1258b9b9-1e84-4372-acf1-a1fd996d11fd-c000.snappy.parquet (55226001 bytes)\n",
      " - Initial_DF/_SUCCESS (0 bytes)\n",
      " - Initial_DF/part-00000-8cdbc3b8-9b0f-4628-ab8d-0b16abe27485-c000.snappy.parquet (63404120 bytes)\n",
      " - Initial_DF/part-00001-8cdbc3b8-9b0f-4628-ab8d-0b16abe27485-c000.snappy.parquet (363178471 bytes)\n",
      " - Initial_DF/part-00002-8cdbc3b8-9b0f-4628-ab8d-0b16abe27485-c000.snappy.parquet (464407051 bytes)\n",
      " - Initial_DF/part-00003-8cdbc3b8-9b0f-4628-ab8d-0b16abe27485-c000.snappy.parquet (458263637 bytes)\n",
      " - Initial_DF/part-00004-8cdbc3b8-9b0f-4628-ab8d-0b16abe27485-c000.snappy.parquet (518011690 bytes)\n",
      " - Initial_DF/part-00005-8cdbc3b8-9b0f-4628-ab8d-0b16abe27485-c000.snappy.parquet (487023444 bytes)\n",
      " - Nearby_Hotspots_DF/_SUCCESS (0 bytes)\n",
      " - Nearby_Hotspots_DF/part-00000-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (99005313 bytes)\n",
      " - Nearby_Hotspots_DF/part-00001-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (96136455 bytes)\n",
      " - Nearby_Hotspots_DF/part-00002-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (95612920 bytes)\n",
      " - Nearby_Hotspots_DF/part-00003-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (94437818 bytes)\n",
      " - Nearby_Hotspots_DF/part-00004-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (59645124 bytes)\n",
      " - Nearby_Hotspots_DF/part-00005-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (57512241 bytes)\n",
      " - Nearby_Hotspots_DF/part-00006-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (59734780 bytes)\n",
      " - Nearby_Hotspots_DF/part-00007-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (57486455 bytes)\n",
      " - Nearby_Hotspots_DF/part-00008-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (57130309 bytes)\n",
      " - Nearby_Hotspots_DF/part-00009-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (56991210 bytes)\n",
      " - Nearby_Hotspots_DF/part-00010-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (55922138 bytes)\n",
      " - Nearby_Hotspots_DF/part-00011-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (114031649 bytes)\n",
      " - Nearby_Hotspots_DF/part-00012-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (111542744 bytes)\n",
      " - Nearby_Hotspots_DF/part-00013-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (109336120 bytes)\n",
      " - Nearby_Hotspots_DF/part-00014-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (108933585 bytes)\n",
      " - Nearby_Hotspots_DF/part-00015-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (109435553 bytes)\n",
      " - Nearby_Hotspots_DF/part-00016-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (108008516 bytes)\n",
      " - Nearby_Hotspots_DF/part-00017-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (101122538 bytes)\n",
      " - Nearby_Hotspots_DF/part-00018-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (94693045 bytes)\n",
      " - Nearby_Hotspots_DF/part-00019-b74b8232-52a6-4c2b-a42b-b0ff5aa9d2e8-c000.snappy.parquet (46357174 bytes)\n",
      " - Streamlit_Tips_Estimate_DF/_SUCCESS (0 bytes)\n",
      " - Streamlit_Tips_Estimate_DF/part-00000-5e1409c2-32c7-4586-a9e4-253b050da64b-c000.snappy.parquet (4047280 bytes)\n",
      " - Streamlit_Tips_Estimate_DF/part-00001-5e1409c2-32c7-4586-a9e4-253b050da64b-c000.snappy.parquet (3891962 bytes)\n",
      " - Streamlit_Tips_Estimate_DF/part-00002-5e1409c2-32c7-4586-a9e4-253b050da64b-c000.snappy.parquet (4066659 bytes)\n",
      " - Streamlit_Tips_Estimate_DF/part-00003-5e1409c2-32c7-4586-a9e4-253b050da64b-c000.snappy.parquet (4069443 bytes)\n",
      " - Streamlit_Tips_Estimate_DF/part-00004-5e1409c2-32c7-4586-a9e4-253b050da64b-c000.snappy.parquet (3904457 bytes)\n",
      " - Streamlit_Tips_Estimate_DF/part-00005-5e1409c2-32c7-4586-a9e4-253b050da64b-c000.snappy.parquet (3889056 bytes)\n",
      " - Streamlit_Tips_Estimate_DF/part-00006-5e1409c2-32c7-4586-a9e4-253b050da64b-c000.snappy.parquet (4051398 bytes)\n",
      " - Streamlit_Tips_Estimate_DF/part-00007-5e1409c2-32c7-4586-a9e4-253b050da64b-c000.snappy.parquet (3897001 bytes)\n",
      " - Streamlit_Tips_Estimate_DF/part-00008-5e1409c2-32c7-4586-a9e4-253b050da64b-c000.snappy.parquet (680515 bytes)\n",
      " - Tip_Prediction_Model_DF/_SUCCESS (0 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00000-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (10447042 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00001-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (10136108 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00002-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (10073926 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00003-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (10032669 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00004-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (6350692 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00005-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (6135301 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00006-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (6365291 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00007-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (6084438 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00008-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (6076887 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00009-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (6054153 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00010-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (5970850 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00011-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (12080933 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00012-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (11788869 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00013-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (11556015 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00014-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (11520387 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00015-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (11574988 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00016-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (11375079 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00017-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (10680065 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00018-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (10019566 bytes)\n",
      " - Tip_Prediction_Model_DF/part-00019-bed33e07-62a7-486a-bd8f-b66ea04ffaf0-c000.snappy.parquet (4930037 bytes)\n",
      " - location_probabilities_in_borough/_SUCCESS (0 bytes)\n",
      " - location_probabilities_in_borough/part-00000-f3bc4000-08a9-4c73-a623-ae42ae2ac62e-c000.snappy.parquet (218941 bytes)\n",
      " - taxi_zone_lookup.csv (12331 bytes)\n",
      "============================================================\n",
      "NYC Taxi Parquet Upload Complete\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from minio import Minio\n",
    "\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(\"CONNECTING TO MINIO\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    logger.info(\"Initializing MinIO client\")\n",
    "    logger.info(f\"Endpoint: minio:9000\")\n",
    "    \n",
    "    minio_client = Minio(\n",
    "        \"minio:9000\",\n",
    "        access_key=\"minioadmin\",\n",
    "        secret_key=\"minioadmin123\",\n",
    "        secure=False\n",
    "    )\n",
    "    logger.info(\"✓ MinIO client connected successfully\")\n",
    "    \n",
    "    bucket_name = \"nyc-taxi\"\n",
    "    logger.info(f\"Listing objects in bucket: {bucket_name}\")\n",
    "    \n",
    "    object_count = 0\n",
    "    total_size = 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Objects inside '{bucket_name}':\")\n",
    "    \n",
    "    for obj in minio_client.list_objects(bucket_name, recursive=True):\n",
    "        print(f\" - {obj.object_name} ({obj.size} bytes)\")\n",
    "        object_count += 1\n",
    "        total_size += obj.size\n",
    "    \n",
    "    logger.info(f\"✓ Bucket listing complete\")\n",
    "    logger.info(f\"  - Total objects: {object_count}\")\n",
    "    logger.info(f\"  - Total size: {total_size:,} bytes ({total_size/(1024**3):.2f} GB)\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"NYC Taxi Parquet Upload Complete\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"✗ Failed to connect to MinIO or list objects: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46d66ca-0baf-4945-aeda-67cb42b3085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(\"READING 2023 DATA WITH SCHEMA ADJUSTMENTS\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Read January separately\n",
    "    logger.info(\"Reading January 2023 data (special schema)\")\n",
    "    df_jan = spark.read.parquet(\"s3a://nyc-taxi/2023/yellow_tripdata_2023-01.parquet\")\n",
    "    jan_count = df_jan.count()\n",
    "    logger.info(f\"✓ January data loaded: {jan_count:,} rows\")\n",
    "    \n",
    "    logger.info(\"Applying schema transformations to January data\")\n",
    "    df_jan = df_jan \\\n",
    "        .withColumn(\"VendorID\", col(\"VendorID\").cast(\"integer\")) \\\n",
    "        .withColumn(\"passenger_count\", col(\"passenger_count\").cast(\"long\")) \\\n",
    "        .withColumn(\"RatecodeID\", col(\"RatecodeID\").cast(\"long\")) \\\n",
    "        .withColumn(\"PULocationID\", col(\"PULocationID\").cast(\"integer\")) \\\n",
    "        .withColumn(\"DOLocationID\", col(\"DOLocationID\").cast(\"integer\")) \\\n",
    "        .withColumnRenamed(\"airport_fee\", \"Airport_fee\")\n",
    "    logger.info(\"✓ Schema transformations applied\")\n",
    "    \n",
    "    # Read Feb-Dec\n",
    "    logger.info(\"Reading February-December 2023 data\")\n",
    "    df_rest = spark.read.parquet(\n",
    "        \"s3a://nyc-taxi/2023/yellow_tripdata_2023-0[2-9].parquet\",\n",
    "        \"s3a://nyc-taxi/2023/yellow_tripdata_2023-1[0-2].parquet\"\n",
    "    )\n",
    "    rest_count = df_rest.count()\n",
    "    logger.info(f\"✓ Feb-Dec data loaded: {rest_count:,} rows\")\n",
    "    \n",
    "    # Union them\n",
    "    logger.info(\"Merging January with Feb-Dec data\")\n",
    "    df1 = df_jan.unionByName(df_rest)\n",
    "    df1_count = df1.count()\n",
    "    logger.info(f\"✓ 2023 data merged: {df1_count:,} rows\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"✗ Failed to read 2023 data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f98e0d69-c5f9-4c7e-9169-6e8e72e0030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(\"COMBINING DATA FROM ALL YEARS\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Read 2024 data\n",
    "    logger.info(\"Reading 2024 data\")\n",
    "    df2 = spark.read.parquet(\"s3a://nyc-taxi/2024/*.parquet\")\n",
    "    df2_count = df2.count()\n",
    "    logger.info(f\"✓ 2024 data loaded: {df2_count:,} rows\")\n",
    "    \n",
    "    # Union 2023 and 2024\n",
    "    logger.info(\"Merging 2023 and 2024 data\")\n",
    "    df_1_2 = df1.union(df2)\n",
    "    df_1_2_count = df_1_2.count()\n",
    "    logger.info(f\"✓ 2023-2024 merged: {df_1_2_count:,} rows\")\n",
    "    \n",
    "    # Add cbd_congestion_fee column for 2023-2024\n",
    "    logger.info(\"Adding 'cbd_congestion_fee' column to 2023-2024 data\")\n",
    "    df_1_2 = df_1_2.withColumn('cbd_congestion_fee', lit(0.0))\n",
    "    logger.info(\"✓ Column added\")\n",
    "    \n",
    "    # Read 2025 data\n",
    "    logger.info(\"Reading 2025 data\")\n",
    "    df3 = spark.read.parquet(\"s3a://nyc-taxi/2025/*.parquet\")\n",
    "    df3_count = df3.count()\n",
    "    logger.info(f\"✓ 2025 data loaded: {df3_count:,} rows\")\n",
    "    \n",
    "    # Final union\n",
    "    logger.info(\"Merging all years (2023-2025)\")\n",
    "    df = df_1_2.union(df3)\n",
    "    final_count = df.count()\n",
    "    \n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(\"✓ ALL DATA COMBINED SUCCESSFULLY\")\n",
    "    logger.info(f\"  - 2023 rows: {df1_count:,}\")\n",
    "    logger.info(f\"  - 2024 rows: {df2_count:,}\")\n",
    "    logger.info(f\"  - 2025 rows: {df3_count:,}\")\n",
    "    logger.info(f\"  - TOTAL rows: {final_count:,}\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    final_count\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"✗ Failed to combine yearly data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd68f17-fa0a-42bb-954e-c0dab1597488",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Optimizing DataFrame partitions (coalescing to 6 partitions)\")\n",
    "df = df.coalesce(6)\n",
    "logger.info(\"✓ DataFrame coalesced to 6 partitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b91dae80-79b8-4109-a50b-8a50ae1d9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=\"*60)\n",
    "logger.info(\"SAVING COMBINED DATASET TO S3\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    output_path = \"s3a://nyc-taxi/Initial_DF\"\n",
    "    logger.info(f\"Writing to: {output_path}\")\n",
    "    logger.info(f\"Total rows to write: {final_count:,}\")\n",
    "    logger.info(\"Mode: overwrite\")\n",
    "    logger.info(\"Format: parquet\")\n",
    "    \n",
    "    df.write \\\n",
    "      .mode(\"overwrite\") \\\n",
    "      .parquet(output_path)\n",
    "    \n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(\"✓ DATASET SAVED SUCCESSFULLY\")\n",
    "    logger.info(f\"  - Location: {output_path}\")\n",
    "    logger.info(f\"  - Total rows: {final_count:,}\")\n",
    "    logger.info(f\"  - Format: Parquet\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"✗ Failed to save dataset: {str(e)}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
